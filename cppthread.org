* capturing by reference into a detached thread is dangerous:

Don't capture local variables by reference into a detached thread--they might be gone.
It's safe for members via this (assuming the object lives long enough).
std::thread([this, notifyFun]() { ...  notifyFun();}).detach();

* start a new detch thread is async
#+begin_src cpp
// the aller should not access full content of use the variable being modified until notified!
void HistoryManager::filterModifyItemThread(const std::wstring& pat, std::function<void()> notify) {
  std::thread([notify, this]() {
    for (const auto& item : this->items_) {
      if (string_util::fuzzy_match(pat, item)) {
        std::lock_guard<std::mutex> lock(filtered_items_mtx);
        this->filtered_items_.push_back(item);
      }
      notify();
    }).detach();
#+end_src
}
* pass args to thread function
never Pass Non-copable/Movable Object by value
| What you want to pass                  | Correct way in thread pool               | Notes                            |
| std::mutex/std::atomic                 | std::ref(obj) or [&]{ }                  | Always by reference              |
| const std::unique_ptr<T>&              | std::cref(obj) or [&]{ }                 | By const reference               |
| std::unique_ptr<T> (want to own/move)  | std::move(obj) or [x = std::move(obj)]{} | Leaves source null               |
| const std::vector<std::unique_ptr<T>>& | std::cref(obj) or [&]{ }                 | Can't copy vector of unique_ptrs |
Never pass non-copyable things (like mutex, unique_ptr, atomic) by value: use references (std::ref/std::cref), or lambda [&].
To move unique_ptrs, use std::move.
If you just want to read (not own), pass const references and use std::cref or capture by ref

void worker(
    int id,
    std::mutex& mtx,                         // non-copyable
    std::atomic<int>& counter,               // non-copyable
    const std::unique_ptr<Object>& uref,     // non-copyable (const ref)
    const std::vector<std::unique_ptr<Object>>& vuref, // non-copyable (const ref to vector of unique_ptrs)
    std::unique_ptr<Object> obj
) {
    std::lock_guard<std::mutex> lock(mtx);
    std::cout << "Thread " << id << ": value="
              << (uref ? uref->val : -1)
              << ", vector size=" << vuref.size()
              << ", counter=" << counter.load() << std::endl;
}

** Use std::ref / std::cref
std::thread t(worker,
    1,
    std::ref(mtx),
    std::ref(counter),
    std::cref(uobj),
    std::cref(vobj),
    std::move(uobj))
** use lambda
std::thread t([&, u = std::move(uobj)]{
    worker(1, mtx, counter, uobj, vobj, std::move(u));
});

The lambda [&] will capture everything by reference, avoiding any copy attempt of non-copyable types.
pool.enqueue([&, max_depth] {fd_search_threaded(subdir, pattern, gitignore_rules, collector, pool, active_tasks, output_mtx, max_depth);});
** error
 pass uncopable object by value, triggering copy
 use of deleted function ‘std::atomic<int>::atomic(const std::atomic<int>&)’
 use of deleted function ‘std::mutex::mutex(const std::mutex&)’
* thread
** c++98
#include <queue>
#include <pthread.h>
#include <string>

class DirQueue {
    std::queue<std::string> q;  // using string instead of fs::path
    pthread_mutex_t m;
    pthread_cond_t cv;
    bool finished;

public:
    DirQueue() : finished(false) {
        pthread_mutex_init(&m, NULL);
        pthread_cond_init(&cv, NULL);
    }

    ~DirQueue() {
        pthread_mutex_destroy(&m);
        pthread_cond_destroy(&cv);
    }

    void push(const std::string& p) {
        pthread_mutex_lock(&m);
        q.push(p);
        pthread_cond_signal(&cv);  // equivalent to notify_one()
        pthread_mutex_unlock(&m);
    }

    bool pop(std::string& p) {
        pthread_mutex_lock(&m);
        while (q.empty() && !finished) { // while loop protects against spurious wakeups, don't use if
            pthread_cond_wait(&cv, &m);
        }
        if (q.empty()) {
            pthread_mutex_unlock(&m);
            return false;
        }
        p = q.front();
        q.pop();
        pthread_mutex_unlock(&m);
        return true;
    }

    void set_finished() {
        pthread_mutex_lock(&m);
        finished = true;
        pthread_cond_broadcast(&cv);  // equivalent to notify_all()
        pthread_mutex_unlock(&m);
    }

    // Disable copying
    DirQueue(const DirQueue&) = delete;
    DirQueue& operator=(const DirQueue&) = delete;
};


*** Manual Mutex Management:
No lock_guard or unique_lock - must manually lock/unlock
Need explicit pthread_mutex_lock()/pthread_mutex_unlock()
Condition Variable Handling:
pthread_cond_wait() requires the mutex to be locked first

*** No built-in predicate check (must use a while loop)
pthread_cond_signal() = notify_one()
pthread_cond_broadcast() = notify_all()

*** Initialization/Cleanup:
Must explicitly initialize/destroy mutex and condition variable
Constructor/Destructor handles this

*** Error Handling:
pthread functions return error codes (ignored here for simplicity)
you'd check these return values

*** No Move Semantics:
Pre-C++11, so no move constructors/assignment
Explicitly delete copy operations to prevent copying
** mordern c++
class DirQueue {
    std::queue<fs::path> q;
    std::mutex m;
    std::condition_variable cv;
    bool finished = false;
public:
    void push(const fs::path& p) {
        std::lock_guard<std::mutex> lock(m);
        q.push(p);
        cv.notify_one();
    }
    bool pop(fs::path& p) {
        std::unique_lock<std::mutex> lock(m);
        cv.wait(lock, [&]{ return !q.empty() || finished; });
        if (q.empty()) return false;
        p = q.front(); q.pop();
        return true;
    }
    void set_finished() {
        std::lock_guard<std::mutex> lock(m);
        finished = true;
        cv.notify_all();
    }
};

*** condition_variable
A std::condition_variable is a synchronization primitive that allows threads to wait for a particular condition to become true. It's always used together with a mutex.

Threads can wait on a condition variable (cv.wait())

Other threads can notify waiting threads when the condition might have changed (cv.notify_one() or cv.notify_all())

*** lock_guard
Used to avoid busy waiting (constantly checking a condition in a loop)
std::lock_guard is a simple RAII (Resource Acquisition Is Initialization) wrapper for a mutex:

*** std::unique_lock is similar to lock_guard but more flexible:
Can be locked/unlocked multiple times
Can be moved (transfer ownership)
Required for use with condition variables (cv.wait() needs to be able to unlock/lock)

** Spurious Wakeups
wake up some thread by OS even they are waiting for some condition variable
The operating system or hardware decided to wake the thread anyway

** Lost Wakeup
the notification happens before wait,  the signal is lost

Condition variables don't have memory - they only signal threads that are currently waiting at the moment of notification. If no threads are waiting when notify_one() is called:

The notification has no effect
The signal disappears into the void
Future waiters won't know about it

Predicates Prevent This
The correct version with a predicate solves this:

std::unique_lock<std::mutex> lock(m);
cv.wait(lock, []{ return !queue.empty(); });
===>or
while(!predicate()) {
    cv.wait(lock);
}
** predicate() value before wait()
*** true:
not block
returns right away
not unlock the mutex or waiting on the condition variable.
goon to process with shared resource
*** false:
block, unlock the mutex, put in sleep
When notified (possibly spuriously), it reacquires the mutex, and rechecks predicate()

* windows thread before std::thread
 Windows API: CreateThread, CRITICAL_SECTION (or HANDLE with CreateMutex), and CreateEvent/Condition Variables (though condition variables arrived late in Windows).
Synchronization: Use CRITICAL_SECTION or HANDLE mutex for protecting shared data (like your pending_work integer).
Pass all your parameters as pointers, packed in a struct, because Windows thread functions accept a void* argument.

* linux thread before std::thread
| Modern                  | Pre-C++11 Replacement |
| std::thread             | pthread_t             |
| std::mutex              | pthread_mutex_t       |
| std::condition_variable | pthread_cond_t        |
| std::atomic<int>        | int + mutex           |
| std::ref                | pointer               |

#include <pthread.h>
#include <vector>
#include <string>
#include <cstdio>

struct WorkItem {
    std::string path;
    int depth;
    WorkItem(const std::string& p, int d) : path(p), depth(d) {}
};
class DirQueue {
public:
    void push(const WorkItem& wi) {/* ... */}
    // ...
};

// This struct holds all the arguments needed by the worker thread
struct WorkerArgs {
    DirQueue* dir_queue;
    std::string* pattern;
    std::vector<std::string>* gitignore_rules;
    int max_depth;
    int* pending_work;
    pthread_mutex_t* pending_work_mtx;
    pthread_mutex_t* output_mtx;
};

void* worker(void* arg_void) {
    WorkerArgs* args = static_cast<WorkerArgs*>(arg_void);
    // Use args->dir_queue, args->pattern, etc.
    // For pending_work, protect access with *pending_work_mtx
    return nullptr;
}

int main() {
    DirQueue dir_queue;
    std::string pattern = "foo";
    std::vector<std::string> gitignore_rules;
    int max_depth = 5;
    int pending_work = 1; // not atomic, so needs protected access

    pthread_mutex_t output_mtx = PTHREAD_MUTEX_INITIALIZER;
    pthread_mutex_t pending_work_mtx = PTHREAD_MUTEX_INITIALIZER;

    // Add initial directory to queue
    dir_queue.push(WorkItem("start_dir", 0));

    // Create worker threads
    int num_threads = 4;
    std::vector<pthread_t> workers(num_threads);
    std::vector<WorkerArgs> worker_args(num_threads);
    for (int i = 0; i < num_threads; ++i) {
        worker_args[i] = {
            &dir_queue,
            &pattern,
            &gitignore_rules,
            max_depth,
            &pending_work,
            &pending_work_mtx,
            &output_mtx
        };
        pthread_create(&workers[i], nullptr, worker, &worker_args[i]);
    }

    // join
    for (int i = 0; i < num_threads; ++i) {
        pthread_join(workers[i], nullptr);
    }
    return 0;
}

* mutable

mutable std::mutex items_mtx; // mutable 允许 const 成员函数加锁

const std::deque<std::wstring>& HistoryManager::all() const {
    std::lock_guard<std::mutex> lock(items_mtx);
    return items_;
}

* two var, two lock
std::thread([&, filterDone, this]() {
    if (pat.empty()) {
        std::lock_guard<std::mutex> lock(filtered_items_mtx);
        this->filtered_items_ = this->items_; // 读取权限冲突
    }
});

* thread safe
#+begin_src cpp

// size() and [] are thread safe, but not the combination
auto sz = history_.size();
if (idx >= 0 && idx < (int)sz) {
    std::wstring sel = history_[idx];
    history_.add(sel);
}
#+end_src

Each Individual Call Is Thread-Safe…
Each call to size() and operator[] is thread-safe as you lock around the underlying container.

...But Not the Combo
NO. The sequence is NOT thread-safe, due to a classic "check-then-use" data race.

# **
** with functor
void with_items(std::function<void(const std::deque<std::wstring>&)> fn) const {
    std::lock_guard<std::mutex> lock(filtered_items_mtx);
    fn(filtered_items_);
}
** template
template<typename Func>
void with_items(Func&& fn) const {
    std::lock_guard<std::mutex> lock(filtered_items_mtx);
    fn(filtered_items_);
}
** do not need move a functor
with_items(lambda is ok)
with_items(std::move(lambda)); unnecessary

`std::move` is generally used when you want to **move** an object into a function (e.g., when passing a container as an rvalue).

#+begin_src cpp
std::vector<int> v = ...;
do_something_with_items(std::move(v));
#+end_src
But for lambdas, you don’t need `std::move` on the lambda **unless** you are moving a named lambda already defined elsewhere (very unusual).

** move-capture in a lambda
If you're trying to move some object into your lambda (not into with_items), you can move-capture it like this (C++14 and higher):

#+begin_src cpp
auto foo = std::make_unique<MyClass>();
history_.with_items([bar = std::move(foo)](const auto& items) {
    // Use bar inside here: bar is moved into the lambda's closure
});
#+end_src
** return mutext protected reference is dangerous
#+begin_src cpp
const std::deque<std::wstring>& HistoryManager::all() const {
    std::lock_guard<std::mutex> lock(filtered_items_mtx);
    return filtered_items_;
}
#+end_src
As soon as the function returns, the lock is released, and any code that then accesses the returned reference is not protected by the mutex. If other threads modify filtered_items_ concurrently, this leads to undefined behavior and possible crashes.

- return by value
- define a with_items function, pass in a callback

* pit
    在history模式下 输入c: 会调用history.filterAsync(callback),这里启动一个线程执行过滤，然后执行callback
在callback里会更新UI界面。
但是紧接着输入 \  , 变成了 c:\  ，模式变成了filebrowser, filebrowser会执行它的filter，过滤出c盘内容更新到界面上。
这时候会出现(迅速输入c:\时)无法显示c盘内容。因为实际上显示了，被history调用的callback的更新覆盖了ui
处理方法是在callback中检查当前的mode
另外也许可以不在callback中直接操作ui，而是postmessage到ui线程，接收到消息时根据实际mode处理(未尝试)
// When done (result_ptr could be some pointer or just 0)
PostMessage(hwndMainWindow, WM_APP + 1, (WPARAM)result_ptr, 0);
// in wndproc
case WM_APP+1:
    {
        std::unique_ptr<std::vector<FileEntry>> results(reinterpret_cast<std::vector<FileEntry>*>(wParam));
        // Use *results...
        // Your code to set browser_.results() and update ListView ...
    }

* process in parallel
#+begin_src cpp

#include <future>
// simplified: read file to buffer, then split lines
std::vector<std::wstring> load_lines_parallel(const std::wstring& filename) {
  std::wifstream in(filename);
  if (!in) return {};
  std::vector<std::wstring> lines;
  std::wstring line;
  while (std::getline(in, line)) lines.push_back(std::move(line));

  // process (e.g. filter non-empty) in parallel
  size_t n = lines.size();
  size_t num_threads = std::thread::hardware_concurrency();
  std::vector<std::future<std::vector<std::wstring>>> futures;
  size_t chunk = n / num_threads;
  for (size_t i = 0; i < num_threads; ++i) {
    size_t b = i * chunk, e = (i == num_threads-1) ? n : (i+1)*chunk;
    futures.push_back(std::async([b, e, &lines] {
      std::vector<std::wstring> result;
      for (size_t j = b; j < e; ++j)
        if (!lines[j].empty()) result.push_back(lines[j]);
      return result;
    }));
  }
  // gather all results
  std::vector<std::wstring> filtered;
  for (auto& fut : futures) {
    auto tmp = fut.get();
    filtered.insert(filtered.end(), std::make_move_iterator(tmp.begin()), std::make_move_iterator(tmp.end()));
  }
  return filtered;
}
#+end_src

* don't lock a mutex twice in the same thread
from ui, call fun1 lock mtx, in fun1 call fun2, and fun2 tries to lock the mtx. ---> error. nested locking.
to support nested locking, use std::recursive_mutex

if fun1 lock mtx, the later fun2 get called. this is fine. fun2 will wait for fun1 to finish

* typical thread class
#+begin_src cpp
#include <atomic>
#include <chrono>
#include <string>
#include <iostream>

ClipboardManager::ClipboardManager(HWND hwnd, Database* db) : hwnd_(hwnd), db_(db), running_(false) {}

void ClipboardManager::Start() {
    running_ = true;
    thread_ = std::thread(&ClipboardManager::Monitor, this);
}

void ClipboardManager::Stop() {
    running_ = false;
    if (thread_.joinable())
        thread_.join();
}

void ClipboardManager::Monitor() {
    AddClipboardFormatListener(hwnd_);
    MSG msg;
    while (running_) {
      // ..
        }
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    }
    RemoveClipboardFormatListener(hwnd_);
}
#+end_src

* std::async
#+BEGIN_SRC cpp
#include <future>
#include <iostream>

int task() { return 123; }

int main() {
// std::launch::async | std::launch::deferred (the default)
    std::future<int> fut = std::async(std::launch::async, task); // Launches 'task' asynchronously
    // Do other work here...
    int value = fut.get();  // Blocks if the task hasn't finished, then gets result
    std::cout << value << std::endl; // prints 123
}

#+END_SRC

fut.get(): Waits for the async task to finish, then gets the int result.
fut.wait(): Waits for the task to finish, but does not get the result.
fut.valid(): True if the future is still associated with a result.
std::future<int> is a "promise to deliver an int later".
You retrieve the result with .get() after the async task finishes.
* wait removing finishes before saving
void HistoryManager::remove(int idx){
// removing may be time cousuming, put it in bg thread? and save operation should be waiting if it does not finish
items_->erase(std::remove(items_->begin(), items_->end(), text), items_->end());
}

void HistoryManager::save() {
std::wofstream out(L"alfred_history.txt");
for (const auto& s : *items_) out << s << L"\n";
}

** use mutext to achieve synchronization
std::lock_guard<std::mutex> lock(data_mutex_); lock mtx in each function. save will wait if the mtx has been locked
** remove in bg
*** std::async
#+BEGIN_SRC cpp
std::future<void> items_erase_task_;

void HistoryManager::remove(int idx){
    // Start erase in a background thread using std::async
    items_erase_task_ = std::async(std::launch::async, [this, text] {
        std::lock_guard<std::mutex> lock2(items_mtx);
        items_->erase(std::remove(items_->begin(), items_->end(), text), items_->end());
    });
}

// Ensure previous erase completes before saving
void HistoryManager::save() {
    if (items_erase_task_.valid()) {
        items_erase_task_.wait();
    }
    std::lock_guard<std::mutex> lock(items_mtx);
    std::wofstream out(L"alfred_history.txt");
    for (const auto& s : *items_) out << s << L"\n";
}
#+END_SRC

*** std::thread
#+BEGIN_SRC cpp
std::thread items_erase_thread_;

void HistoryManager::remove(int idx){
    // If previous thread is still running, wait for it
    if (items_erase_thread_.joinable()) items_erase_thread_.join();

    items_erase_thread_ = std::thread([this, text] {
        std::lock_guard<std::mutex> lock2(items_mtx);
        items_->erase(std::remove(items_->begin(), items_->end(), text), items_->end());
    });
}

// Wait for background erase before saving
void HistoryManager::save() {
    if (items_erase_thread_.joinable()) items_erase_thread_.join();
    std::lock_guard<std::mutex> lock(items_mtx);
    std::wofstream out(L"alfred_history.txt");
    for (const auto& s : *items_) out << s << L"\n";
}
#+END_SRC
