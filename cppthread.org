* capturing by reference into a detached thread is dangerous:

Don't capture local variables by reference into a detached thread--they might be gone.
It's safe for members via this (assuming the object lives long enough).
std::thread([this, notifyFun]() { ...  notifyFun();}).detach();

* start a new detch thread is async
#+begin_src cpp
// the aller should not access full content of use the variable being modified until notified!
void HistoryManager::filterModifyItemThread(const std::wstring& pat, std::function<void()> notify) {
  std::thread([notify, this]() {
    for (const auto& item : this->items_) {
      if (string_util::fuzzy_match(pat, item)) {
        std::lock_guard<std::mutex> lock(filtered_items_mtx);
        this->filtered_items_.push_back(item);
      }
      notify();
    }).detach();
#+end_src
}
* pass args to thread function
never Pass Non-copable/Movable Object by value
| What you want to pass                  | Correct way in thread pool               | Notes                            |
| std::mutex/std::atomic                 | std::ref(obj) or [&]{ }                  | Always by reference              |
| const std::unique_ptr<T>&              | std::cref(obj) or [&]{ }                 | By const reference               |
| std::unique_ptr<T> (want to own/move)  | std::move(obj) or [x = std::move(obj)]{} | Leaves source null               |
| const std::vector<std::unique_ptr<T>>& | std::cref(obj) or [&]{ }                 | Can't copy vector of unique_ptrs |
Never pass non-copyable things (like mutex, unique_ptr, atomic) by value: use references (std::ref/std::cref), or lambda [&].
To move unique_ptrs, use std::move.
If you just want to read (not own), pass const references and use std::cref or capture by ref

void worker(
    int id,
    std::mutex& mtx,                         // non-copyable
    std::atomic<int>& counter,               // non-copyable
    const std::unique_ptr<Object>& uref,     // non-copyable (const ref)
    const std::vector<std::unique_ptr<Object>>& vuref, // non-copyable (const ref to vector of unique_ptrs)
    std::unique_ptr<Object> obj
) {
    std::lock_guard<std::mutex> lock(mtx);
    std::cout << "Thread " << id << ": value="
              << (uref ? uref->val : -1)
              << ", vector size=" << vuref.size()
              << ", counter=" << counter.load() << std::endl;
}

** Use std::ref / std::cref
std::thread t(worker,
    1,
    std::ref(mtx),
    std::ref(counter),
    std::cref(uobj),
    std::cref(vobj),
    std::move(uobj))
*** why ref to wrap mutex and conditon_variable
    std::mutex and std::condition_variable are non-copyable and non-movable
    std::ref wraps an object in a reference wrapper. When you call std::thread(worker, std::ref(cv), std::ref(mtx));, you're telling std::thread:
    Don't try to copy/move cv and mtx. Instead, pass them as references to the worker function.
*** The mechanics:
std::ref(obj) returns a std::reference_wrapper<T>.
When the thread infrastructure unpacks this to pass to the function, it gives your function a reference to the original object.

** use lambda
std::thread t([&, u = std::move(uobj)]{
    worker(1, mtx, counter, uobj, vobj, std::move(u));
});

The lambda [&] will capture everything by reference, avoiding any copy attempt of non-copyable types.
pool.enqueue([&, max_depth] {fd_search_threaded(subdir, pattern, gitignore_rules, collector, pool, active_tasks, output_mtx, max_depth);});
** error
 pass uncopable object by value, triggering copy
 use of deleted function ‘std::atomic<int>::atomic(const std::atomic<int>&)’
 use of deleted function ‘std::mutex::mutex(const std::mutex&)’
* thread
** c++98
#include <queue>
#include <pthread.h>
#include <string>

class DirQueue {
    std::queue<std::string> q;  // using string instead of fs::path
    pthread_mutex_t m;
    pthread_cond_t cv;
    bool finished;

public:
    DirQueue() : finished(false) {
        pthread_mutex_init(&m, NULL);
        pthread_cond_init(&cv, NULL);
    }

    ~DirQueue() {
        pthread_mutex_destroy(&m);
        pthread_cond_destroy(&cv);
    }

    void push(const std::string& p) {
        pthread_mutex_lock(&m);
        q.push(p);
        pthread_cond_signal(&cv);  // equivalent to notify_one()
        pthread_mutex_unlock(&m);
    }

    bool pop(std::string& p) {
        pthread_mutex_lock(&m);
        while (q.empty() && !finished) { // while loop protects against spurious wakeups, don't use if
            pthread_cond_wait(&cv, &m);
        }
        if (q.empty()) {
            pthread_mutex_unlock(&m);
            return false;
        }
        p = q.front();
        q.pop();
        pthread_mutex_unlock(&m);
        return true;
    }

    void set_finished() {
        pthread_mutex_lock(&m);
        finished = true;
        pthread_cond_broadcast(&cv);  // equivalent to notify_all()
        pthread_mutex_unlock(&m);
    }

    // Disable copying
    DirQueue(const DirQueue&) = delete;
    DirQueue& operator=(const DirQueue&) = delete;
};


*** Manual Mutex Management:
No lock_guard or unique_lock - must manually lock/unlock
Need explicit pthread_mutex_lock()/pthread_mutex_unlock()
Condition Variable Handling:
pthread_cond_wait() requires the mutex to be locked first

*** No built-in predicate check (must use a while loop)
pthread_cond_signal() = notify_one()
pthread_cond_broadcast() = notify_all()

*** Initialization/Cleanup:
Must explicitly initialize/destroy mutex and condition variable
Constructor/Destructor handles this

*** Error Handling:
pthread functions return error codes (ignored here for simplicity)
you'd check these return values

*** No Move Semantics:
Pre-C++11, so no move constructors/assignment
Explicitly delete copy operations to prevent copying
** mordern c++
class DirQueue {
    std::queue<fs::path> q;
    std::mutex m;
    std::condition_variable cv;
    bool finished = false;
public:
    void push(const fs::path& p) {
        std::lock_guard<std::mutex> lock(m);
        q.push(p);
        cv.notify_one();
    }
    bool pop(fs::path& p) {
        std::unique_lock<std::mutex> lock(m);
        cv.wait(lock, [&]{ return !q.empty() || finished; });
        if (q.empty()) return false;
        p = q.front(); q.pop();
        return true;
    }
    void set_finished() {
        std::lock_guard<std::mutex> lock(m);
        finished = true;
        cv.notify_all();
    }
};

*** condition_variable
A std::condition_variable is a synchronization primitive that allows threads to wait for a particular condition to become true. It's always used together with a mutex.

Threads can wait on a condition variable (cv.wait())

Other threads can notify waiting threads when the condition might have changed (cv.notify_one() or cv.notify_all())

*** lock_guard
Used to avoid busy waiting (constantly checking a condition in a loop)
std::lock_guard is a simple RAII (Resource Acquisition Is Initialization) wrapper for a mutex:

*** std::unique_lock is similar to lock_guard but more flexible:
Can be locked/unlocked multiple times
Can be moved (transfer ownership)
Required for use with condition variables (cv.wait() needs to be able to unlock/lock)

** Spurious Wakeups
wake up some thread by OS even they are waiting for some condition variable
The operating system or hardware decided to wake the thread anyway

** Lost Wakeup
the notification happens before wait,  the signal is lost

Condition variables don't have memory - they only signal threads that are currently waiting at the moment of notification. If no threads are waiting when notify_one() is called:

The notification has no effect
The signal disappears into the void
Future waiters won't know about it

Predicates Prevent This
The correct version with a predicate solves this:

std::unique_lock<std::mutex> lock(m);
cv.wait(lock, []{ return !queue.empty(); });
===>or
while(!predicate()) {
    cv.wait(lock);
}
** predicate() value before wait()
*** true:
not block
returns right away
not unlock the mutex or waiting on the condition variable.
goon to process with shared resource
*** false:
block, unlock the mutex, put in sleep
When notified (possibly spuriously), it reacquires the mutex, and rechecks predicate()

** in preC++, how to do this:
    DirQueue dir_queue;
    std::atomic<int> pending_work{1};  // Start with 1 for the initial directory
    std::mutex output_mtx;
    std::mutex worker_mtx;
    std::condition_variable worker_cv;

    // Add initial directory to queue
    dir_queue.push(WorkItem(start_dir, 0));

    // Create worker threads
    std::vector<std::thread> workers;
    workers.reserve(num_threads);

    for (int i = 0; i < num_threads; ++i) {
        workers.emplace_back(worker,
            std::ref(dir_queue),
            std::ref(pattern),
            std::ref(gitignore_rules),
            max_depth,
            std::ref(pending_work),
            std::ref(output_mtx)
        );
    }

*** old cpp
#include <pthread.h>
#include <vector>
#include <string>
#include <cstdio>

struct WorkItem {
    std::string path;
    int depth;
    WorkItem(const std::string& p, int d) : path(p), depth(d) {}
};
class DirQueue {
public:
    void push(const WorkItem& wi) {/* ... */}
    // ...
};

// This struct holds all the arguments needed by the worker thread
struct WorkerArgs {
    DirQueue* dir_queue;
    std::string* pattern;
    std::vector<std::string>* gitignore_rules;
    int max_depth;
    int* pending_work;
    pthread_mutex_t* pending_work_mtx;
    pthread_mutex_t* output_mtx;
};

void* worker(void* arg_void) {
    WorkerArgs* args = static_cast<WorkerArgs*>(arg_void);
    // Use args->dir_queue, args->pattern, etc.
    // For pending_work, protect access with *pending_work_mtx
    return nullptr;
}

int main() {
    DirQueue dir_queue;
    std::string pattern = "foo";
    std::vector<std::string> gitignore_rules;
    int max_depth = 5;
    int pending_work = 1; // not atomic, so needs protected access

    pthread_mutex_t output_mtx = PTHREAD_MUTEX_INITIALIZER;
    pthread_mutex_t pending_work_mtx = PTHREAD_MUTEX_INITIALIZER;

    // Add initial directory to queue
    dir_queue.push(WorkItem("start_dir", 0));

    // Create worker threads
    int num_threads = 4;
    std::vector<pthread_t> workers(num_threads);
    std::vector<WorkerArgs> worker_args(num_threads);
    for (int i = 0; i < num_threads; ++i) {
        worker_args[i] = {
            &dir_queue,
            &pattern,
            &gitignore_rules,
            max_depth,
            &pending_work,
            &pending_work_mtx,
            &output_mtx
        };
        pthread_create(&workers[i], nullptr, worker, &worker_args[i]);
    }

    // join
    for (int i = 0; i < num_threads; ++i) {
        pthread_join(workers[i], nullptr);
    }
    return 0;
}

*** on windows
int main() {
    DirQueue dir_queue;
    std::string pattern = "foo";
    std::vector<std::string> gitignore_rules;
    int max_depth = 5;
    int pending_work = 1;

    CRITICAL_SECTION output_cs;
    CRITICAL_SECTION pending_work_cs;
    InitializeCriticalSection(&output_cs);
    InitializeCriticalSection(&pending_work_cs);

    // Add initial dir to queue
    dir_queue.push(WorkItem("start_dir", 0));

    int num_threads = 4;
    std::vector<HANDLE> workers(num_threads);
    std::vector<WorkerArgs> worker_args(num_threads);

    for (int i = 0; i < num_threads; ++i) {
        worker_args[i] = {
            &dir_queue,
            &pattern,
            &gitignore_rules,
            max_depth,
            &pending_work,
            &pending_work_cs,
            &output_cs
        };
        workers[i] = CreateThread(
            nullptr,            // default security
            0,                  // default stack size
            WorkerThread,       // thread function
            &worker_args[i],    // parameter to function
            0,                  // default creation flags
            nullptr);           // thread identifier not needed
    }

    // Wait for workers to finish
    WaitForMultipleObjects(num_threads, workers.data(), TRUE, INFINITE);

    // Clean up
    for (int i = 0; i < num_threads; ++i)
        CloseHandle(workers[i]);
    DeleteCriticalSection(&output_cs);
    DeleteCriticalSection(&pending_work_cs);
    return 0;
}
* windows thread before std::thread
 Windows API: CreateThread, CRITICAL_SECTION (or HANDLE with CreateMutex), and CreateEvent/Condition Variables (though condition variables arrived late in Windows).
Synchronization: Use CRITICAL_SECTION or HANDLE mutex for protecting shared data (like your pending_work integer).
Pass all your parameters as pointers, packed in a struct, because Windows thread functions accept a void* argument.

* linux thread before std::thread
| Modern                  | Pre-C++11 Replacement |
| std::thread             | pthread_t             |
| std::mutex              | pthread_mutex_t       |
| std::condition_variable | pthread_cond_t        |
| std::atomic<int>        | int + mutex           |
| std::ref                | pointer               |

#include <pthread.h>
#include <vector>
#include <string>
#include <cstdio>

struct WorkItem {
    std::string path;
    int depth;
    WorkItem(const std::string& p, int d) : path(p), depth(d) {}
};
class DirQueue {
public:
    void push(const WorkItem& wi) {/* ... */}
    // ...
};

// This struct holds all the arguments needed by the worker thread
struct WorkerArgs {
    DirQueue* dir_queue;
    std::string* pattern;
    std::vector<std::string>* gitignore_rules;
    int max_depth;
    int* pending_work;
    pthread_mutex_t* pending_work_mtx;
    pthread_mutex_t* output_mtx;
};

void* worker(void* arg_void) {
    WorkerArgs* args = static_cast<WorkerArgs*>(arg_void);
    // Use args->dir_queue, args->pattern, etc.
    // For pending_work, protect access with *pending_work_mtx
    return nullptr;
}

int main() {
    DirQueue dir_queue;
    std::string pattern = "foo";
    std::vector<std::string> gitignore_rules;
    int max_depth = 5;
    int pending_work = 1; // not atomic, so needs protected access

    pthread_mutex_t output_mtx = PTHREAD_MUTEX_INITIALIZER;
    pthread_mutex_t pending_work_mtx = PTHREAD_MUTEX_INITIALIZER;

    // Add initial directory to queue
    dir_queue.push(WorkItem("start_dir", 0));

    // Create worker threads
    int num_threads = 4;
    std::vector<pthread_t> workers(num_threads);
    std::vector<WorkerArgs> worker_args(num_threads);
    for (int i = 0; i < num_threads; ++i) {
        worker_args[i] = {
            &dir_queue,
            &pattern,
            &gitignore_rules,
            max_depth,
            &pending_work,
            &pending_work_mtx,
            &output_mtx
        };
        pthread_create(&workers[i], nullptr, worker, &worker_args[i]);
    }

    // join
    for (int i = 0; i < num_threads; ++i) {
        pthread_join(workers[i], nullptr);
    }
    return 0;
}

* mutable

mutable std::mutex items_mtx; // mutable 允许 const 成员函数加锁

const std::deque<std::wstring>& HistoryManager::all() const {
    std::lock_guard<std::mutex> lock(items_mtx);
    return items_;
}

* two var, two lock
std::thread([&, filterDone, this]() {
    if (pat.empty()) {
        std::lock_guard<std::mutex> lock(filtered_items_mtx);
        this->filtered_items_ = this->items_; // 读取权限冲突
    }
});

* thread safe
#+begin_src cpp

// size() and [] are thread safe, but not the combination
auto sz = history_.size();
if (idx >= 0 && idx < (int)sz) {
    std::wstring sel = history_[idx];
    history_.add(sel);
}
#+end_src

Each Individual Call Is Thread-Safe…
Each call to size() and operator[] is thread-safe as you lock around the underlying container.

...But Not the Combo
NO. The sequence is NOT thread-safe, due to a classic "check-then-use" data race.

# **
** with functor
void with_items(std::function<void(const std::deque<std::wstring>&)> fn) const {
    std::lock_guard<std::mutex> lock(filtered_items_mtx);
    fn(filtered_items_);
}
** template
template<typename Func>
void with_items(Func&& fn) const {
    std::lock_guard<std::mutex> lock(filtered_items_mtx);
    fn(filtered_items_);
}
** do not need move a functor
with_items(lambda is ok)
with_items(std::move(lambda)); unnecessary

`std::move` is generally used when you want to **move** an object into a function (e.g., when passing a container as an rvalue).

#+begin_src cpp
std::vector<int> v = ...;
do_something_with_items(std::move(v));
#+end_src
But for lambdas, you don’t need `std::move` on the lambda **unless** you are moving a named lambda already defined elsewhere (very unusual).

** move-capture in a lambda
If you're trying to move some object into your lambda (not into with_items), you can move-capture it like this (C++14 and higher):

#+begin_src cpp
auto foo = std::make_unique<MyClass>();
history_.with_items([bar = std::move(foo)](const auto& items) {
    // Use bar inside here: bar is moved into the lambda's closure
});
#+end_src
** return mutext protected reference is dangerous
#+begin_src cpp
const std::deque<std::wstring>& HistoryManager::all() const {
    std::lock_guard<std::mutex> lock(filtered_items_mtx);
    return filtered_items_;
}
#+end_src
As soon as the function returns, the lock is released, and any code that then accesses the returned reference is not protected by the mutex. If other threads modify filtered_items_ concurrently, this leads to undefined behavior and possible crashes.

- return by value
- define a with_items function, pass in a callback

* pit
    在history模式下 输入c: 会调用history.filterAsync(callback),这里启动一个线程执行过滤，然后执行callback
在callback里会更新UI界面。
但是紧接着输入 \  , 变成了 c:\  ，模式变成了filebrowser, filebrowser会执行它的filter，过滤出c盘内容更新到界面上。
这时候会出现(迅速输入c:\时)无法显示c盘内容。因为实际上显示了，被history调用的callback的更新覆盖了ui
处理方法是在callback中检查当前的mode
另外也许可以不在callback中直接操作ui，而是postmessage到ui线程，接收到消息时根据实际mode处理(未尝试)
// When done (result_ptr could be some pointer or just 0)
PostMessage(hwndMainWindow, WM_APP + 1, (WPARAM)result_ptr, 0);
// in wndproc
case WM_APP+1:
    {
        std::unique_ptr<std::vector<FileEntry>> results(reinterpret_cast<std::vector<FileEntry>*>(wParam));
        // Use *results...
        // Your code to set browser_.results() and update ListView ...
    }

* process in parallel
#+begin_src cpp

#include <future>
// simplified: read file to buffer, then split lines
std::vector<std::wstring> load_lines_parallel(const std::wstring& filename) {
  std::wifstream in(filename);
  if (!in) return {};
  std::vector<std::wstring> lines;
  std::wstring line;
  while (std::getline(in, line)) lines.push_back(std::move(line));

  // process (e.g. filter non-empty) in parallel
  size_t n = lines.size();
  size_t num_threads = std::thread::hardware_concurrency();
  std::vector<std::future<std::vector<std::wstring>>> futures;
  size_t chunk = n / num_threads;
  for (size_t i = 0; i < num_threads; ++i) {
    size_t b = i * chunk, e = (i == num_threads-1) ? n : (i+1)*chunk;
    futures.push_back(std::async([b, e, &lines] {
      std::vector<std::wstring> result;
      for (size_t j = b; j < e; ++j)
        if (!lines[j].empty()) result.push_back(lines[j]);
      return result;
    }));
  }
  // gather all results
  std::vector<std::wstring> filtered;
  for (auto& fut : futures) {
    auto tmp = fut.get();
    filtered.insert(filtered.end(), std::make_move_iterator(tmp.begin()), std::make_move_iterator(tmp.end()));
  }
  return filtered;
}
#+end_src

* don't lock a mutex twice in the same thread
from ui, call fun1 lock mtx, in fun1 call fun2, and fun2 tries to lock the mtx. ---> error. nested locking.
to support nested locking, use std::recursive_mutex

if fun1 lock mtx, the later fun2 get called. this is fine. fun2 will wait for fun1 to finish

* typical thread class
#+begin_src cpp
#include <atomic>
#include <chrono>
#include <string>
#include <iostream>

ClipboardManager::ClipboardManager(HWND hwnd, Database* db) : hwnd_(hwnd), db_(db), running_(false) {}

void ClipboardManager::Start() {
    running_ = true;
    thread_ = std::thread(&ClipboardManager::Monitor, this);
}

void ClipboardManager::Stop() {
    running_ = false;
    if (thread_.joinable())
        thread_.join();
}

void ClipboardManager::Monitor() {
    AddClipboardFormatListener(hwnd_);
    MSG msg;
    while (running_) {
      // ..
        }
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    }
    RemoveClipboardFormatListener(hwnd_);
}
#+end_src

* std::async
#+BEGIN_SRC cpp
#include <future>
#include <iostream>

int task() { return 123; }

int main() {
// std::launch::async | std::launch::deferred (the default)
    std::future<int> fut = std::async(std::launch::async, task); // Launches 'task' asynchronously
    // Do other work here...
    int value = fut.get();  // Blocks if the task hasn't finished, then gets result
    std::cout << value << std::endl; // prints 123
}

#+END_SRC

fut.get(): Waits for the async task to finish, then gets the int result.
fut.wait(): Waits for the task to finish, but does not get the result.
fut.valid(): True if the future is still associated with a result.
std::future<int> is a "promise to deliver an int later".
You retrieve the result with .get() after the async task finishes.
* wait removing finishes before saving
void HistoryManager::remove(int idx){
// removing may be time cousuming, put it in bg thread? and save operation should be waiting if it does not finish
items_->erase(std::remove(items_->begin(), items_->end(), text), items_->end());
}

void HistoryManager::save() {
std::wofstream out(L"alfred_history.txt");
for (const auto& s : *items_) out << s << L"\n";
}

** use mutext to achieve synchronization
std::lock_guard<std::mutex> lock(data_mutex_); lock mtx in each function. save will wait if the mtx has been locked
** remove in bg
*** std::async
#+BEGIN_SRC cpp
std::future<void> items_erase_task_;

void HistoryManager::remove(int idx){
    // Start erase in a background thread using std::async
    items_erase_task_ = std::async(std::launch::async, [this, text] {
        std::lock_guard<std::mutex> lock2(items_mtx);
        items_->erase(std::remove(items_->begin(), items_->end(), text), items_->end());
    });
}

// Ensure previous erase completes before saving
void HistoryManager::save() {
    if (items_erase_task_.valid()) {
        items_erase_task_.wait();
    }
    std::lock_guard<std::mutex> lock(items_mtx);
    std::wofstream out(L"alfred_history.txt");
    for (const auto& s : *items_) out << s << L"\n";
}
#+END_SRC

*** std::thread
#+BEGIN_SRC cpp
std::thread items_erase_thread_;

void HistoryManager::remove(int idx){
    // If previous thread is still running, wait for it
    if (items_erase_thread_.joinable()) items_erase_thread_.join();

    items_erase_thread_ = std::thread([this, text] {
        std::lock_guard<std::mutex> lock2(items_mtx);
        items_->erase(std::remove(items_->begin(), items_->end(), text), items_->end());
    });
}

// Wait for background erase before saving
void HistoryManager::save() {
    if (items_erase_thread_.joinable()) items_erase_thread_.join();
    std::lock_guard<std::mutex> lock(items_mtx);
    std::wofstream out(L"alfred_history.txt");
    for (const auto& s : *items_) out << s << L"\n";
}
#+END_SRC

* mutex
C++互斥锁底层主要依赖：

原子指令（硬件保证原子性），如 x86 的 lock cmpxchg
操作系统同步原语（pthread_mutex、CriticalSection，可能还用 futex/futex2 等优化器）
用户态与内核态混合（快速路径用 CAS/Spin，慢速路径挂起等待）

std::mutex 是对这些工具的高级封装，屏蔽了具体细节及跨平台差异。

** 递归互斥锁
#include <mutex>
#include <iostream>

std::recursive_mutex rmtx;

void foo(int depth) {
    if (depth <= 0) return;
    rmtx.lock();
    std::cout << "foo depth " << depth << std::endl;
    foo(depth - 1); // 递归调用，仍会加锁
    rmtx.unlock();
}

int main() {
    foo(5);
    return 0;
}
** 读写锁
c++17
#include <shared_mutex>
#include <map>
#include <string>

class ConfigTable {
    std::map<std::string, int> table;
    mutable std::shared_mutex mtx;
public:
    // 读操作
    int get(std::string key) const {
        std::shared_lock lock(mtx); // 读锁
        auto it = table.find(key);
        return it == table.end() ? -1 : it->second;
    }

    // 写操作
    void set(std::string key, int value) {
        std::unique_lock lock(mtx); // 写锁
        table[key] = value;
    }
};
** 自己用原子变量实现自旋锁
自旋锁是一种轻量级的锁机制，适用于临界区代码极短、线程持锁时间很少的场景。它的特点是——线程在获取不到锁时不会睡眠阻塞，而是循环“自旋”不断尝试获取锁，直到成功。

一般用于多核系统内核、线程库或者高性能场景。
若锁持有时间较长，频繁自旋会浪费CPU，性能反而不如普通互斥锁。

std::atomic_flag lock = ATOMIC_FLAG_INIT;
void lock() {
// test_and_set是原子操作，无需内核介入
    while (lock.test_and_set(std::memory_order_acquire)); // memory order acquire 保证 lock 之后的读取不会被重排到 lock 之前
}
void unlock() {
    lock.clear(std::memory_order_release);// memory_order_release 保证unlock之前的数据写入不会重排到unlock之后(重排是因为编译器优化)
}

| 机制     | 优点                                 | 缺点                       | 适用场景             |
| Spinlock | 用户态，无需系统调用。适合短临界区。 | 锁阻塞时浪费CPU。          | 多核、持锁极短场景   |
| Mutex    | 线程阻塞时释放CPU。                  | 加锁失败进入内核态，开销大 | 适合锁持有较长的场景 |

* remove data in bg :Using std::future with std::async:
#+begin_src cpp
void HistoryManager::remove(int idx){
	if(idx <0 || idx >= filtered_items_->size()) return;
	std::wstring text = ( * filtered_items_)[idx];
	{
		std::lock_guard<std::mutex> lock(filter_mutex_);
		filtered_items_->erase(filtered_items_->begin() + idx);
	}

	{
		std::lock_guard<std::mutex> lock2(items_mtx);
//how to put this erase in bg thread
		items_->erase(std::remove(items_->begin(), items_->end(), text), items_->end());
	}
}

    // using std::future
std::future<void> items_erase_task_;

void HistoryManager::remove(int idx){
    if(idx <0 || idx >= filtered_items_->size()) return;
    std::wstring text = (*filtered_items_)[idx];
    {
        std::lock_guard<std::mutex> lock(filter_mutex_);
        filtered_items_->erase(filtered_items_->begin() + idx);
    }

    // Start erase in a background thread using std::async
    items_erase_task_ = std::async(std::launch::async, [this, text] {
        std::lock_guard<std::mutex> lock2(items_mtx);
        items_->erase(std::remove(items_->begin(), items_->end(), text), items_->end());
    });
}

// Ensure previous erase completes before saving
void HistoryManager::save() {
    if (items_erase_task_.valid()) {
        items_erase_task_.wait();
    }
    std::lock_guard<std::mutex> lock(items_mtx);
    std::wofstream out(L"alfred_history.txt");
    for (const auto& s : *items_) out << s << L"\n";
}


    //  Using std::thread (optional, but harder to manage completion)
std::thread items_erase_thread_;

void HistoryManager::remove(int idx){
    if(idx <0 || idx >= filtered_items_->size()) return;
    std::wstring text = (*filtered_items_)[idx];
    {
        std::lock_guard<std::mutex> lock(filter_mutex_);
        filtered_items_->erase(filtered_items_->begin() + idx);
    }

    // If previous thread is still running, wait for it
    if (items_erase_thread_.joinable()) items_erase_thread_.join();

    items_erase_thread_ = std::thread([this, text] {
        std::lock_guard<std::mutex> lock2(items_mtx);
        items_->erase(std::remove(items_->begin(), items_->end(), text), items_->end());
    });
}

// Wait for background erase before saving
void HistoryManager::save() {
    if (items_erase_thread_.joinable()) items_erase_thread_.join();
    std::lock_guard<std::mutex> lock(items_mtx);
    std::wofstream out(L"alfred_history.txt");
    for (const auto& s : *items_) out << s << L"\n";
}
#+end_src
