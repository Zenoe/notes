                                           + docker container net ns +
                                           |                         |
           172.17.0.1                      |   172.17.0.2            |
        +- docker0 --------- veth123@if5 --|-- eth0@if6              |
        |  (bridge)          (veth pair)   |   (veth pair)           |
        |                                  |                         |
        |  127.0.0.1                       +-------------------------+
routing +- lo
        |  (loopback)
        |
        |  192.168.1.2
        +- ens33
           (physical host interface)

Can you run GUI applications in a Docker container?
https://stackoverflow.com/questions/16296753/can-you-run-gui-applications-in-a-docker-container

docker network ls
# ip link set br100 down
# brctl delbr br100

* docker0 vs br-xx
docker0 bridges your containers network (or any compose networks) to the hosts main network interface meaning your containers can access the network (and internet) and you can access the containers.

The br-xxx interfaces are simply each container or compose network.

* How to Live Tail Docker Logs
docker logs <container ID>
docker logs --follow <container ID>
#1: Display Only the Latest Lines
In some cases, you don’t want to see all logs for a container. Perhaps something happened, and you want to quickly verify the latest 100 logs for your container. In this case, you can use the tail option to specify the number of logs you want to see:

docker logs --tail 100 <container ID>
#2: Stream Logs Until a Specific Point in Time
Docker provides the option to only stream logs from a specific time. For example, logs written during the first three seconds when the container was active can tell you if the container started successfully. In this case, you don’t have to create a never-ending stream of logs. Here, you can use the until option with the follow option. The until option allows you to specify a time span for which the container should print logs to your CLI.

docker logs --follow --until=3s
You can use different notations to designate the timescale. For example, to see the logs for the last 30 minutes, use the following command:

docker logs --follow --until=30m
#3: Stream Logs From a Specific Point in Time
The opposite action is also possible with Docker CLI options. Let’s say you want to see the logs from a specific point in time until now. The since option helps with this task.

docker logs --since 2019-03-02 <container ID>
The accepted format here is YYYY-MM-DDTHH:MM:SS. This means you can specify a very accurate timestamp from which you want to display logs, or a less specific timestamp, as shown in the example above.
* docker run
You will get a list of all local Docker images with the tags specified.

$ docker run image_name:tag_name

If you didn't specify tag_name it will automatically run an image with the 'latest' tag.

Instead of image_name, you can also specify an image ID

$ docker run -i -t ubuntu:12.04 /bin/bash
Without a name, just using the ID:

$ docker run -i -t 8dbd9e392a96 /bin/bash
* create new image from running container
docker commit c5a24953e383 newimagename

install git in the container
docker commit -m "centos with git" -a "qixianhu" 72f1a8a0e394 xianhu/centos:git
m指定说明信息；-a指定用户信息；72f1a8a0e394代表容器的id；xianhu/centos:git指定目标镜像的用户名、仓库名和 tag 信息。注意这里的用户名xianhu，后边会用到。
此时Docker引擎中就有了我们新建的镜像xianhu/centos:git，此镜像和原有的CentOS镜像区别在于多了个Git

And then start a new container from that image:
docker run -it xianhu/centos:git /bin/bash
* proxy
docker这个程序只是一个控制台程序，用于attach，真正操作docker的是运行在后台的docker daemon，也就是我们需要通过systemctl start docker来启动docker daemon。所以说即使我们设置了环境变量http_proxy，那么也只是针对前台docker console使用，而真正访问pull镜像的确是后台的daemon，因此，需要设置daemon访问proxy。

mkdir -p /etc/systemd/system/docker.service.d
vi /etc/systemd/system/docker.service.d/http-proxy.conf

[Service]
Environment="HTTP_PROXY=http://USER:PASSWD@SERVER:PORT/"
Environment="HTTPS_PROXY=http://USER:PASSWD@SERVER:PORT/"
Environment="NO_PROXY=localhost,127.0.0.1,example.com"

systemctl daemon-reload
systemctl restart docker

// check proxy
systemctl show --property=Environment docker
/etc/docker/daemon.json
{
    "registry-mirrors": ["http://mirror.ruijie.com.cn:8090"]
}
* device busy
grep docker /proc/*/mountinfo | grep 05e1d
/proc/15543/mountinfo:163 153 0:46 / /var/lib/docker/overlay/05e1d1e99099f8b69fe5cc92e18139e86502e90e20cba06ee08ae67cfb02a8f2/merged rw,relatime shared:113 - overlay overlay rw,lowerdir=/var/lib/docker/overlay/9ef8e525cd64111ed994c112eaf0278c3aa88c5099f91173fe6367ad0ae183c8/root,upperdir=/var/lib/docker/overlay/05e1d1e99099f8b69fe5cc92e18139e86502e90e20cba06ee08ae67cfb02a8f2/upper,workdir=/var/lib/docker/overlay/05e1d1e99099f8b69fe5cc92e18139e86502e90e20cba06ee08ae67cfb02a8f2/work
ps aux | grep 15543
ntp      15543  0.0  0.0  45200  1920 ?        Ss   Dec05   0:15 /usr/sbin/ntpd -u ntp:ntp -g
root     29959  0.0  0.0 112712   968 pts/0    S+   13:19   0:00 grep --color=auto 15543
systemctl stop ntpd
ps aux | grep 15543
root     30213  0.0  0.0 112708   968 pts/0    S+   13:20   0:00 grep --color=auto 15543
rm -rf 05e1d1e99099f8b69fe5cc92e18139e86502e90e20cba06ee08ae67cfb02a8f2

* centos enable/disable user namespace
reboot is needed
grubby --args="user_namespace.enable=1" --update-kernel="$(grubby --default-kernel)"
grubby --remove-args="user_namespace.enable=1" --update-kernel="$(grubby --default-kernel)"

* docker top [container id] to find process running in docker container
* basic
docker search centos    # 查看centos镜像是否存在
docker image ls
commands to verify that the cryptographic IDs of the shared layers are the same.
docker history [image id]

* docker run -it centos:latest /bin/bash
-i和-t。前者表示打开并保持stdout，后者表示分配一个终端（pseudo-tty）。此时如果使用exit退出，则容器的状态处于Exit，而不是后台运行。如果想让容器一直运行，而不是停止，可以使用快捷键 ctrl+p ctrl+q 退出，此时容器的状态为Up。
* added the following to /etc/sysctl.conf: net.ipv4.ip_forward=1
* docker ps -a | awk {'print $1'} | xargs docker rm
* local image save / load
docker pull nginx:latest
docker save nginx > ./nginx.tar
docker load < nginx.tar
* 镜像和容器 导出和导入的区别
1）容器导入 是将当前容器 变成一个新的镜像  export/import
2）镜像导入 是复制的过程 save/load
save 和 export区别：
1）save 保存镜像所有的信息-包含历史
2）export 只导出当前的信息

* Setting up MySQL and importing data within Dockerfile
https://stackoverflow.com/questions/25920029/setting-up-mysql-and-importing-dump-within-dockerfile
Each RUN instruction in a Dockerfile is executed in a different layer

Solution 1: use a one-line RUN
RUN /bin/bash -c "/usr/bin/mysqld_safe --skip-grant-tables &" && \
  sleep 5 && \
  mysql -u root -e "CREATE DATABASE mydb" && \
  mysql -u root mydb < /tmp/dump.sql

  mysql -u root -e "CREATE DATABASE mydb" && \
  mysql -u root main < /tmp/dump.sql

Solution 2: use a script
Create an executable script init_db.sh:

#!/bin/bash
/usr/bin/mysqld_safe --skip-grant-tables &
sleep 5
mysql -u root -e "CREATE DATABASE mydb"
mysql -u root mydb < /tmp/dump.sql
Add these lines to your Dockerfile:

ADD init_db.sh /tmp/init_db.sh
RUN /tmp/init_db.sh

* Cannot start service xxx: invalid header field value "oci runtime error: container_linux.go:247
reasen: docker-compose.yml 中有这一条
- /etc/timezone:/etc/timezone:ro
but /etc/timezone 不存在
solution:
ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/timezone

* a Tutorial on How to use the NGINX Official Docker Image
https://blog.docker.com/2015/04/tips-for-deploying-nginx-official-image-with-docker/
 # docker run --name mynginx1 -P -d nginx

This command creates a container named mynginx1 based on the NGINX image and runs it in detached mode

The NGINX image exposes ports 80 and 443 in the container and the -P option tells Docker to map those ports to ports on the Docker host that are randomly selected from the range between 49153 and 65535. We do this because if we create multiple NGINX containers on the same Docker host, we create a conflict on ports 80 and 443. The port mappings are dynamic and are set each time the container is started or restarted. If you want the port mappings to be static, set them manually with the -p option.

We can run docker ps to verify that the container was created and is running, and to see the port mappings:
 # docker ps

CONTAINER ID  IMAGE         COMMAND               CREATED         STATUS PORTS                                         NAMES

fcd1fb01b145  nginx:latest  "nginx -g 'daemon of  16 seconds ago  Up 15 seconds

0.0.0.0:49166->443/tcp, 0.0.0.0:49167->80/tcp mynginx1

We can also verify that NGINX is running by making an HTTP request to port 49167

 # curl http://localhost:49167

<!DOCTYPE html>
<html>
...

It is common to have SSH access to NGINX instances, but Docker containers are generally intended to be for a single purpose (in this case running NGINX) so the NGINX image does not have OpenSSH installed and for normal operations there is no need to get shell access directly to the NGINX container. We will use other methods supported by Docker. For a detailed discussion of alternatives to SSH access, see Why you don’t need to run SSHd in your Docker Containers.

Managing Content and Configuration Files

There are multiple ways you can manage the NGINX content and configuration files and we will cover a few options:

Maintain the Content and Configuration on the Docker Host

mount a local directory on the Docker host to a directory in the container. If the content on the Docker host is in the local directory /var/www and the configuration files are in /var/nginx/conf, we run the command:

# docker run --name mynginx2 -v /var/www:/usr/share/nginx/html:ro \
-v /var/nginx/conf:/etc/nginx:ro -P -d nginx

Now any change made to the files in the local directories /var/www and /var/nginx/conf on the Docker host are reflected in the directories /usr/share/nginx/html and /etc/nginx in the container. The :ro option causes these directors to be read only inside the container.


Copy the Files from the Docker Host

Another option is to have Docker copy the content and configuration files from a local directory on the Docker host when a container is created. Once a container is created, the files are maintained by creating a new container when the files change or by modifying the files in the container. A simple way to copy the files is to create a Dockerfile to generate a new Docker image, based on the NGINX image from Docker Hub. When copying files in the Dockerfile, the path to the local directory is relative to the build context where the Dockerfile is located. For this example, the content is in the content directory and the configuration files are in the conf directory, both in the same directory as theDockerfile. The NGINX image has the default NGINX configuration files, including default.conf and example_ssl.conf in/etc/nginx/conf.d. Since we want to use the configuration files from the host, we include commands in the followingDockerfile to delete the default files:

FROM nginx

RUN rm /etc/nginx/conf.d/default.conf

RUN rm /etc/nginx/conf.d/examplessl.conf

COPY content /usr/share/nginx/html

COPY conf /etc/nginx
We can then create our own NGINX image by running the following command from the directory where the Dockerfileis located:

# docker build -t mynginximage1.
Note the period (“.”) at the end of the command. This tells Docker that the build context is the current directory. The build context contains the Dockerfile and the directories to be copied. Now we can create a container using the image by running the command:

# docker run --name mynginx3 -P -d mynginximage1
If we want to make changes to the files in the container, we use a helper container as described below.

Maintain Files in the Container
As mentioned previously, we are not able to get SSH access to the NGINX container, so if we want to edit the content or configuration files directly we can use a helper container that has shell access. In order for the helper container to have access to the files, we must create a new image that has the proper volumes specified for the image. Assuming we want to copy the files as in the example above, while also specifying volumes for the content and configuration files, we use the following Dockerfile:

FROM nginx

 COPY content /usr/share/nginx/html

 COPY conf /etc/nginx

 VOLUME /usr/share/nginx/html

 VOLUME /etc/nginx
We then create the new NGINX image by running the following command (again note the final period):

# docker build -t mynginximage2 .
Now we create an NGINX container using the image by running the command:

# docker run --name mynginx4 -P -d mynginximage2
We then start a helper container with a shell and access the content and configuration directories of the NGINX container we created in the previous example by running the command:

# docker run -i -t --volumes-from mynginx4 --name mynginx4files debian /bin/bash
 root@b1cbbad63dd1:/#
This creates an interactive container named mynginx4_files that runs in the foreground with a persistent standard input (-i) and a tty (-t) and mounts all the volumes defined in the container mynginx4 as local directories in the newmynginx4_files container. This container uses the Debian image from Docker Hub, which is the same operating system used by the NGINX image. Since all of the examples shown so far use the NGINX image and therefore Debian, it is more efficient to use Debian for the helper container rather then having Docker load another operating system. After the container is created, it runs the bash shell, which presents a shell prompt for the container that you can use to modify the files as needed. You can also install other tools, such as Puppet or Chef, in the container to manage these files. If you exit the shell by running the exit command, the container terminates. If you want to exit while leaving the container running, use Control-p followed by Control-q. The container can be started and stopped with the following commands:

# docker start mynginx4files
and

# docker stop mynginx4files
Shell access can be regained to a running container with the command:

# docker attach mynginx4files

Managing Logging
Default Logging
The NGINX image is configured to send the main NGINX access and error logs to the Docker log collector by default. This is done by linking them to stdout and stderr, which causes all messages from both logs to be stored in the file/var/lib/docker/containers/\<container id\>/\<container id\>-json.log on the Docker Host. \<container id\> is the long-form Container Id returned when you create a container. You can display the long-form Id for a container with the command:

# docker inspect --format '{{ .Id }}' <container name>
You can use both the Docker command line and the Docker Remote API to extract the log messages. From the command line run the command:

# docker logs <container name>
To enable the Docker Remote API, add the following line to the file /etc/default/docker:

DOCKEROPTS='-H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock'
When Docker is restarted, it listens for HTTP API requests on port 4243 (you can specify a different port) and also on a socket. To get all the messages, you can issue the GET request:

http://<docker host>:4243/containers/<container name>/logs?stdout=1&stderr=1
To include only access log messages in the output, include only stdout=1; to limit the output to error log messages, include only stderr=1. To learn about other available options, see the Docker documentation.

Customized Logging
If you want to implement another method of log collection, or if you want to configure logging differently at various levels in the NGINX configuration (such as servers and locations), you can use a volume for the directory or directories in which to store the log files in the container. You can then use a helper container to access the log files and use whatever logging tools you like. To implement this, create a new image that contains the volume or volumes for the logging files. For example, to configure NGINX to store log files in /var/log/nginx/log, we start with the Dockerfile shown in the earlier example of copying files from the Docker host to the container and simply add a volume declaration for this directory:

FROM nginx
 COPY content /usr/share/nginx/html
 COPY conf /etc/nginx
 VOLUME /var/log/nginx/log
We can then create an image as described above and using this image create an NGINX container and a helper container that have access to the log directory. This helper container can have any desired logging tools installed.


Controlling NGINX
Since we do not have access to the command line of the NGINX container directly, we cannot use the nginx command to control NGINX. Fortunately NGINX can be controlled by signals and Docker provides kill command for sending signals to a container. For example, to reload the NGINX configuration run the command:

docker kill -s HUP <container name>
If you want to restart the NGINX process, restart the container by running the command:

docker restart <container name>
* rm all
docker stop $(docker ps -a -q)
docker rm $(docker ps -a -q)
lsof -t -i:8082
* docker run -it -p 28080:80 --name tomcattest ruijie/tomcat-jcr
docker run -it -v /opt/idata-install/services/topbi/topbi-jcr-server:/usr/local/jcr --name tomcattest -p  8082:8082 -d  openjdk:8-jre /bin/bash && docker exec -it tomcattest bash
* nohup … & doesn't work as expected in docker script
nohup only redirects the command's output if it's going to a terminal. If the output is already going to another type of file (e.g. regular file or a pipe), nohup assumes that this is desired and does not redirect to nohup.out.

By default, docker run runs the command via a socket (connecting the host with the virtual environment — that's how they communicate). A socket isn't a terminal so nohup doesn't perform any redirection.

If you run docker run -t then Docker will emulate a terminal in the container and so nohup will redirect to nohup.out. If you don't pass a command name then docker acts as if you'd used docker run -t bash.

The best solution is to explicitly redirect the output of the command to your choice of log file. Don't forget to redirect stderr as well. That way you'll know where they're going.

nohup awk 'BEGIN { while (c++<50) print "y" }' >myscript.log 2>&1 &
* connect mysql from within docker
https://stackoverflow.com/questions/24319662/from-inside-of-a-docker-container-how-do-i-connect-to-the-localhost-of-the-mach
docker run --net="host"
Alternatively you can run a docker container with network settings set to host. Such a container will share the network stack with the docker host and from the container point of view, localhost (or 127.0.0.1) will refer to the docker host.

Be aware that any port opened in your docker container would be opened on the docker host. And this without requiring the -p or -P docker run option.

docker-compose.yml
add:
network_mode: "host"

* curl -L https://github.com/docker/compose/releases/download/1.20.0-rc1/docker-compose-`uname -s`-`uname -m` > ./docker-compose
$ sudo mv ./docker-compose /usr/bin/docker-compose
$ sudo chmod +x /usr/bin/docker-compose

* Using Docker-Compose, how to execute multiple commands
command: bash -c "python manage.py migrate && python manage.py runserver 0.0.0.0:8000"

Same example in multilines:
command: >
    bash -c "python manage.py migrate
    && python manage.py runserver 0.0.0.0:8000"

* docker-compose networking
By default Compose sets up a single network for your app. Each container for a service joins the default network and is both reachable by other containers on that network, and discoverable by them at a hostname identical to the container name.
https://docs.docker.com/compose/networking/
port mapping:
HOST_PORT:CONTAINER_PORT
* 修改 docker-compose.yml 单个服务配置，docker-compose restart rbis 不生效
 docker-compose up -d --build rbis

The other answers to restarting a single node are on target,
docker-compose restart worker. That will bounce that container, but
not include any changes, even if you rebuilt it separately. You can
manually stop, rm, create, and start, but there are much easier
methods.

If you've updated your code, you can do the build and reload in a single step with:

docker-compose up -d --build

That will first rebuild your images from any changed code, which is fast if there are no changes since the cache is reused. And then it
only replaces the changed containers. If your downloaded images are stale, you can precede the above command with:

docker-compose pull
To download any changed images first (the containers won't be restarted until you run a command like the up above). Doing an initial stop is unnecessary.

And to only do this for a single service, follow the up or pull command with the services you want to specify, e.g.:

docker-compose up -d --build worker
* See docker logs
You can start your Docker compose in detached mode and attach yourself to the logs of all container later. If you have enough of watching logs you can detach yourself from the logs output without shutting down your services.
Use docker-compose up -d to start all services in detached mode (-d) (you won't see any logs in detached mode)

Use docker-compose logs -f -t to attach yourself to the logs of all
running services, whereas -f means you follow the log output and the
-t option gives you nice timestamps (See Docker reference)

Use Ctrl + z or Ctrl + c to detach yourself from the log output without shutting down your services
If you're interested in a single container you can use the docker keyword:

Use docker logs -t -f <container-name>
* cannot create network conflicts with network
sudo rm -rf /var/lib/docker/network
sudo systemctl start docker
* docker-compose log
By default docker uses the json-file driver to record your containers logs and the raw json output of the logs can be found in:

/var/lib/docker/containers/[container-id]/[container-id]-json.log
You can get this location by running:

docker inspect --format='{{.LogPath}}' [container-id or container-name]
When you run docker-compose logs [service-name], docker-compose will attach to the service (container) you reference and the LogPrinter object will output the contents of the above file, but formatted so they're easier to read.

Related docs: https://docs.docker.com/compose/compose-file/#logging

** limit the size of log
version: '2'
services:
  my-service:
    image: nginx:alpine
    restart: always
    logging:
      # limit logs retained on host to 25MB
      driver: "json-file"
      options:
        max-size: "500k"
        max-file: "50"

** docker logs -c (clear) <container>  ??

* 修改docker镜像地址（不修改的话 国外的镜像站点很慢的哦）
vi /etc/docker/daemon.json
echo "{\"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\"]}" > /etc/docker/daemon.json
最后，需要重启docker服务 systemctl restart docker.service

* Export the ID of the process that runs the container:
PID=$(docker inspect --format '{{.State.Pid}}' my_container_id)
"Connect" to it by changing namespaces:
nsenter --target $PID --mount --uts --ipc --net --pid

* relocate /lib/docker/
Clean-up any dangling volumes
Clean-up any dangling images
Clean-up any unused containers

systemctl stop docker
vi /lib/systemd/system/docker.service
ExecStart=/usr/bin/dockerd -g /data/data4/docker
rsync -aqx /var/lib/docker/* /data/data4/docker
systemctl daemon-reload
systemctl start docker

* Dockerfile
FROM webdevops/php-apache
RUN apt-get update && apt-get install mysql-client -y

.........
docker build -t php-apache-mysql .

* SELinux is not supported with the overlay2 graph driver on this kernel
According to the [[https://success.docker.com/article/compatibility-matrix][compatibility matrix]] docker-1.13 for CentOS supports only
devicemapper.
bash # cat  /etc/sysconfig/docker-storage
DOCKER_STORAGE_OPTIONS="--storage-driver devicemapper "
* docker network create idatabr --gateway 10.200.255.1 --subnet 10.200.255.0/24
docker network connect idatabr nginx

* Customize the docker0 bridge
https://success.docker.com/article/how-do-i-configure-the-default-bridge-docker0-network-for-docker-engine-to-a-different-subnet
/etc/docker/daemon.json
{
  "bip": "172.26.0.1/16"
}
{
  "bip": "192.168.1.5/24",
  "fixed-cidr": "192.168.1.5/25",
  "fixed-cidr-v6": "2001:db8::/64",
  "mtu": 1500,
  "default-gateway": "10.20.1.1",
  "default-gateway-v6": "2001:db8:abcd::89",
  "dns": ["10.20.1.2","10.20.1.3"]
}
* docker rm -f $(docker ps --all -q -f status=dead)

* network host
In Docker, the host is a machine responsible for running one or more containers. Docker network host, also known as Docker host networking, is a networking mode in which a Docker container shares its network namespace with the host machine.

* docker vs docker.io
docker is a tray plugin, while docker.io is the Docker containerization software.
Ubuntu already had a package called docker so they had to call the package for the Docker container software docker.io
apt-get install docker.io
You will get a package described as "Docker complements kernel namespacing with a high level API which operates at the process level." i.e. the Docker everyone is usually thinking about when they say Docker.
sudo apt-get install docker
You will get a package described as a "System tray for KDE3/GNOME2 applications"
* install
As of my last knowledge update in January 2024, Ubuntu 22.04 had not been released. However, I can provide you with instructions for installing Docker on Ubuntu 20.04 LTS, which was the latest long-term support release at that time. Please note that the steps might need to be adjusted for Ubuntu 22.04 when it becomes available.

Here are the general steps for installing Docker on Ubuntu 20.04:

### 1. Update Package Index

```bash
sudo apt update
```

### 2. Install Required Packages to Enable `apt` to Use a Repository over HTTPS

```bash
sudo apt install apt-transport-https ca-certificates curl software-properties-common
```

### 3. Add Docker’s Official GPG Key

```bash
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
```

### 4. Set Up the Stable Docker Repository

```bash
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
```

### 5. Install Docker Engine

```bash
sudo apt update
sudo apt install docker-ce docker-ce-cli containerd.io
```

### 6. Verify Docker Installation

```bash
sudo docker --version
```

### 7. Manage Docker as a Non-Root User (Optional)

If you want to use Docker as a non-root user, you can add your user to the `docker` group:

```bash
sudo usermod -aG docker your_username
```

Replace `your_username` with your actual username.

### 8. Start and Enable Docker Service

```bash
sudo systemctl start docker
sudo systemctl enable docker
```

After following these steps, Docker should be successfully installed on your Ubuntu system.

Please ensure that you adjust the steps as needed when Ubuntu 22.04 is released, as the package versions and repository URLs might change. Always refer to the official Docker documentation or the specific documentation for the version of Ubuntu you are using for the most up-to-date instructions.
