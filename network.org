* socket
** if (setsockopt(server_socket_, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt)) < 0) {// 出错处理}
SO_REUSEADDR
套接字选项，允许端口被重复使用。
即使 socket 正处于 TIME_WAIT 状态也能快速重新绑定。
常用于服务器开发，服务器程序重启后,会出现“Address already in use”错误。

&opt
选项值的指针。
通常是 int opt = 1;，表示打开 SO_REUSEADDR 选项。
第 4 个参数要求传指针，目的是为了灵活设定不同类型、长度的选项值。

** accept
struct sockaddr_in client_addr;
socklen_t len = sizeof(client_addr);
int client_socket = accept(server_socket_, (struct sockaddr*)&client_addr, &len);

accpet 第三个参数应该是指针，可以外传
输入：告诉 accept client_addr 多大
输出：accept 写入实际地址结构的长度（通常没变化）
*** addr_len 可能会变成 IPv6 的长度
#+BEGIN_SRC c
// 支持 v4 v6 写法
struct sockaddr_storage client_addr;
socklen_t addr_len = sizeof(client_addr);

int client_socket = accept(server_socket_, (struct sockaddr*)&client_addr, &addr_len);

if (client_addr.ss_family == AF_INET) {
    struct sockaddr_in* in = (struct sockaddr_in*)&client_addr;
    // 处理 IPv4 地址
} else if (client_addr.ss_family == AF_INET6) {
    struct sockaddr_in6* in6 = (struct sockaddr_in6*)&client_addr;
    // 处理 IPv6 地址
}

#+END_SRC

**** 如果  server_socket_ 是 AF_INET 类型, 仅监听IPv4, 客户端只有通过 IPv4 才能连上你的这个 socket
sockaddr_in 就足够了
struct sockaddr_in client_addr;
socklen_t len = sizeof(client_addr);
int client_socket = accept(server_socket_, (struct sockaddr*)&client_addr, &len);
**** server_socket_ 是 AF_INET6 类型 socket(AF_INET6, SOCK_STREAM, ...)
假如你仍然声明 struct sockaddr_in client_addr; 用于存储客户端地址
客户端是 IPv6 地址连过来的
accept 实际会写入 sockaddr_in6 结构体内容到这块空间
但是你的空间只有 sizeof(struct sockaddr_in)（16字节），而 IPv6 需要 sizeof(struct sockaddr_in6)（28字节）
写入的时候会溢出/覆盖内存

*** getsockname(target_socket, (sockaddr*)&local_addr, &addr_len);
获取某个 socket 当前绑定的本地地址（即系统给这个 socket 分配了哪个 IP/端口）
最后一个参数返回时被覆盖为实际地址长度
#+BEGIN_SRC c
struct sockaddr_storage local_addr;
socklen_t addr_len = sizeof(local_addr);

getsockname(target_socket, (struct sockaddr*)&local_addr, &addr_len);

// 判断协议族并处理
if (local_addr.ss_family == AF_INET) {
    struct sockaddr_in *addr4 = (struct sockaddr_in*)&local_addr;
    // 解析端口和IP
} else if (local_addr.ss_family == AF_INET6) {
    struct sockaddr_in6 *addr6 = (struct sockaddr_in6*)&local_addr;
    // 解析端口和IPv6
}
#+END_SRC

** listen(sockfd, backlog);
此时，内核为你的这个监听socket维护了两个队列：
- 半连接队列（syn queue）
存放刚刚收到客户端 SYN，还没有收到第三次握手 ACK 的连接，即“半连接”
只完成了握手的第1步和第2步
队列大小通常是系统参数（e.g. /proc/sys/net/ipv4/tcp_max_syn_backlog）
如果满了，新的syn被丢弃
- 全连接队列（accept queue）
存放已完成完整三次握手（SYN, SYN+ACK, ACK）的连接，等待你的程序调用 accept() 去取出来
队列大小由 listen() 的 backlog 参数决定（但受限于 /proc/sys/net/core/somaxconn），Linux下最常见最大128
如果满了，已三次握手的连接也没法再移入队列（新连接会被拒绝或TCP层丢失ACK）。

** SYN泛洪攻击（SYN Flood）
攻击者伪造大量TCP SYN包，发送到服务器监听端口。 整个攻击只发第一个握手包（SYN），不发送有效的ACK回包完成三次握手。
服务器内核收到大量 SYN，把连接状态都暂存到半连接队列 syn queue, 占满后正常客户端连接被丢弃
*** accept并发模型优化
1. 单线程accept（传统模式）
while (1) {
    int client = accept(listenfd, ...);
    // 每次处理一个连接
}
优点：简单稳定
缺点：处理慢，无法分担压力

2. 多线程/多进程accept（并发accept模式）
形式1：多个进程、线程都监听同一端口
for (i = 0; i < N; ++i)
    fork(); // 每个进程都 accept

或者
pthread_create(..., accept_thread, ...);
每个并发单元都可能 accept 到新连接
现代Linux支持多进程/多线程轮流accept，内核用负载均衡算法（称为“惊群”问题已优化，epoll实现中表现更好）
形式2：主线程 accept，分发到线程池
while (1) {
    int client = accept(listenfd, ...);
    put_into_workqueue(client);
}
主线程只负责accept，业务处理交给线程池/工作进程

3. 高性能事件驱动模式（epoll/kqueue）
主线程用 epoll/kqueue 管理多个事件，随时 accept 到新连接，轮流分发到 worker
支持百万级并发连接
例如 nginx/redis 等大负载应用的常见做法：

启动多个 worker 进程/线程都监听同一个 socket
每次新连接由内核算法“分发”给一个 worker
某些场景用 SO_REUSEPORT，让多个监听 socket 并发读写，提升并发，自带负载均衡

4. SO_REUSEPORT新特性
让多个进程/线程可以绑定同一个端口，每个 accept 得到自己的连接
Linux 3.9及以上支持，性能极高、安全无惊群
setsockopt(sockfd, SOL_SOCKET, SO_REUSEPORT, ...);

5. 系统参数优化
backlog 设置为 somaxconn（128/1024/更高）
accept 用 epoll 边缘触发模式（EPOLLET），减少系统调用
accept 结果立刻让 worker 处理，避免主线程阻塞

6. 用户态负载均衡调度
accept 到新连接后分析负载分配（如最少连接数、CPU亲和性、worker状态等）
某些场景用独立 accept 单元、独立处理单元
** connect()
会立即发送SYN
- 发SYN包 到目标服务器
- 等待收到服务器的 SYN+ACK 回复
- 回复 ACK 完成握手
connect() 只有在三次握手全部成功后，才返回成功；否则会返回错误（比如超时、拒绝等）

* 组播： 01:00:5E
* SSL VPN 握手失败
tcp 连接ok udp无法连接（dtls握手失败）
 大网---路由器---sw-----
                 |
               EG2000D（桥模式）

1.UDP的443 端口没映射出去到1443，TCP映射出去了。
2.客户端使用了443端口进行握手(udp),导致隧道无法连接

* icmpv6
   ICMPv6和IVMPv4的校验和的计算方法是不一样的，v6校验范围更广，包含了伪首部，先解释下什么是伪首部。
    伪首部并非TCP&UDP数据报中实际的有效成分。伪首部是一个虚拟的数据结构，其中的信息是从数据报所在IP分组头的分组头中提取的，既不向下传送也不向上递交，而仅仅是为计算校验和。这样的校验和，既校验了TCP&UDP用户数据的源端口号和目的端口号以及TCP&UDP用户数据报的数据部分，又检验了IP数据报的源IP地址和目的地址。伪报头保证TCP&UDP数据单元到达正确的目的地址。因此，伪报头中包含IP地址并且作为计算校验和需要考虑的一部分。最终目的端根据伪报头和数据单元计算校验和以验证通信数据在传输过程中没有改变而且到达了正确的目的地址。伪首部更确切的说是校验和包含的—个96位的伪首标，是个理论上的值，只是理论上它位于TCP&UDP首标的前面。这个伪首标包含了源地址、目的地址、协议和TCP&UDP长度等字段，这使得TCP&UDP能够防止出现路由选择错误的数据段。这些信息由网际协议(IP)承载，通过TCP&UDP网络接口，在IP上运行的TCP&UDP调用参数或者结果中传递。
    上面是copy的百度百科，回到我们的ICMPv6报文来，简单说来，我们的伪首部包含4个部分：sourse address， destination addrss， payload length， next header。大小为16 + 16 + 2 + 1字节。要计算校验和，还需要的信息是ICMPv6首部的内容，其中checksum值在计算之前需要先置为0，为什么就不用解释里吧，呵呵，咱就是算这东西的呀。
    在TCP、UDP和ICMPv6中，in6_chsum()函数提供校验和计算方法，而in6_cksum()函数假定分组是以mbuf结构进行传递的，不适合我们自己做包调试。这里给出我采用的一种方法，参考了http://hi.baidu.com/fleago/blog/item/846e86864489743dc75cc3f4.html，感谢fleago同学。
    我们以如下方法构造一个报文，并给出计算函数：
unsigned char packet_buffer[] = {
   //icmp header 完整的ICMPv6首部，长度不一定是这么长
   0x87, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
   0xfe, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
   0x75, 0xc5, 0xf1, 0x20, 0x80, 0x97, 0x0e, 0x39,

   // pseudo header
   // source addr
   0x20, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
   0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
   // dest addr
   0xff, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
   0x00, 0x00, 0x00, 0x01, 0xff, 0x97, 0x0e, 0x39,
   // payload len
   0x00, 0x00, 0x00, 0x18,
   // next header
   0x00, 0x00, 0x00, 0x3a
};
unsigned short checksum(int len, unsigned char *buffer)
{
	unsigned long cksum = 0;
        unsigned short *p = (unsigned short*)buffer;
        int size = (len >> 1) + (len & 0x1);  // 以两个字节为运算单位，					      // len除以2四舍五入
        while (size > 0) {
		cksum += *p;
		printf("%4x, %8x\n", *p, cksum);
                p ++;
                size --;
        }
        cksum = (cksum >> 16) + (cksum & 0xffff);
        cksum += (cksum >> 16);
        printf("before ~cksum: %8x\n", cksum);
       printf("checksum is (hex, in packet byte seq): %02x, %02x\n", 	      ~cksum & 0xff, ~cksum >> 8);
        return (unsigned short) (~cksum);      // 取补码，和v4不同
} 
* arp
在实现TCP/IP协议的网络环境下，一个ip包走到哪里，要怎么走是靠路由表定义，但是，当ip包到达该网络后，哪台机器响应这个ip包却是靠该ip包中所包含的硬件mac地址来识别。也就是说，只有机器的硬件mac地址和该ip包中的硬件mac地址相同的机器才会应答这个ip包，因为在网络中，每一台主机都会有发送ip包的时候，所以，在每台主机的内存中，都有一个+arp-->+硬件mac+的转换表。通常是动态的转换表（该arp表可以手工添加静态条目）。也就是说，该对应表会被主机在一定的时间间隔后刷新。这个时间间隔就是ARP高速缓存的超时时间。+通常主机在发送一个ip包之前，它要到该转换表中寻找和ip包对应的硬件mac地址，如果没有找到，该主机就发送一个ARP广播包，于是，主机刷新自己的ARP缓存。然后发出该ip包。+了解这些常识后，现在就可以谈在以太网络中如何实现ARP欺骗了，可以看看这样一个例子。&oq=我们先复习一下上面所讲的ARP协议的原理。在实现TCP%2FIP协议的网络环境下，一个ip包走到哪里，要怎么走是靠路由表定义，但是，当ip包到达该网络后，哪台机器响应这个ip包却是靠该ip包中所包含的硬件mac地址来识别。也就是说，只有机器的硬件mac地址和该ip包中的硬件mac地址相同的机器才会应答这个ip包，因为在网络中，每一台主机都会有发送ip包的时候，所以，在每台主机的内存中，都有一个+arp-->+硬件mac+的转换表。通常是动态的转换表（该arp表可以手工添加静态条目）。也就是说，该对应表会被主机在一定的时间间隔后刷新。这个时间间隔就是ARP高速缓存的超时时间。+通常主机在发送一个ip包之前，它要到该转换表中寻找和ip包对应的硬件mac地址，如果没有找到，该主机就发送一个ARP广播包，于是，主机刷新自己的ARP缓存。然后发出该ip包。
* MSG_PEEK
Peeks at an incoming message. The data is treated as unread and the next recv() or similar function shall still return this data.
http://pubs.opengroup.org/onlinepubs/009695399/functions/recv.html

to receive bytes from socket
n = recv(sock, &c, 1, MSG_PEEK);
to get the number of bytes available in the socket without creating 'buffer' 
ioctl(fd,FIONREAD,&bytes_available) , and under windows ioctlsocket(socket,FIONREAD,&bytes_available).
Be warned though, the OS doesn't necessarily guarantee how much data it will buffer for you, so if you are waiting for very much data you are going to be better off reading in data as it comes in and storing it in your own buffer until you have everything you need to process something.

To do this, what is normally done is you simply read chunks at a time, such as

char buf[4096];
ssize_t bytes_read;
do {
     bytes_read = recv(socket, buf, sizeof(buf), 0);
     if (bytes_read > 0) {
         /* do something with buf, such as append it to a larger buffer or
          * process it */
     }
} while (bytes_read > 0);

And if you don't want to sit there waiting for data, you should look into select
or epoll to determine when data is ready to be read or not, and the O_NONBLOCK
flag for sockets is very handy if you want to ensure you never block on a recv.
* sockaddr
"struct sockaddr" is a generic definition. It's used by any socket function that requires an address.

there are possible multiple protocol which all implement the getsockname. And each have themself underling address data structure, 
IPv4 --> sockaddr_in 
IPV6 --> sockaddr_in6
sockaddr_un --> AF_UNIX socket.
sockaddr are used as the common data strut in the signature of those APIs.

A struct sockaddr should generally only be used as the base type for a pointer. It is a structure intended to cover the common initial sequence of the members in the address family specific socket address types (struct sockaddr_un, struct sockaddr_in, struct sockaddr_in6 etc.)
The only member that you can rely on struct sockaddr having is a single sa_family_t, indicating the socket address family. 
The idea is that to obtain a sort of polymorphism - you can have a function that can operate on several different socket address types:

void foo(struct sockaddr *sa)
{
    switch(sa->sin_family)
    {
    case AF_INET: {
        struct sockaddr_in *sa_in = (struct sockaddr_in *)sa;

        /* AF_INET processing */
    }

    case AF_UNIX: {
        struct sockaddr_un *sa_un = (struct sockaddr_un *)sa;

        /* AF_UNIX processing */
    }

/* ... */
* pipe
http://pubs.opengroup.org/onlinepubs/009695399/functions/pipe.html
The pipe() function shall create a pipe and place two file descriptors, one each into the arguments fildes[0] and fildes[1], that refer to the open file descriptions for the read and write ends of the pipe. Their integer values shall be the two lowest available at the time of the pipe() call. The O_NONBLOCK and FD_CLOEXEC flags shall be clear on both file descriptors. (The fcntl() function can be used to set both these flags.)
Using a Pipe to Pass Data Between a Parent Process and a Child Process
The following example demonstrates the use of a pipe to transfer data between a parent process and a child process. Error handling is excluded, but otherwise this code demonstrates good practice when using pipes: after the fork() the two processes close the unused ends of the pipe before they commence transferring data.

#include <stdlib.h>
#include <unistd.h>
...


int fildes[2];
const int BSIZE = 100;
char buf[BSIZE];
ssize_t nbytes;
int status;


status = pipe(fildes);
if (status == -1 ) {
    /* an error occurred */
    ...
}


switch (fork()) {
case -1: /* Handle error */
    break;


case 0:  /* Child - reads from pipe */
    close(fildes[1]);                       /* Write end is unused */
    nbytes = read(fildes[0], buf, BSIZE);   /* Get data from pipe */
    /* At this point, a further read would see end of file ... */
    close(fildes[0]);                       /* Finished with pipe */
    exit(EXIT_SUCCESS);


default:  /* Parent - writes to pipe */
    close(fildes[0]);                       /* Read end is unused */
    write(fildes[1], "Hello world\n", 12);  /* Write data on pipe */
    close(fildes[1]);                       /* Child will see EOF */
    exit(EXIT_SUCCESS);
}
* select
The select() function allows you to implement an event driven design pattern, when you have to deal with multiple event sources.

Let's say you want to write a program that responds to events coming from several event sources e.g. network (via sockets), user input (via stdin), other programs (via pipes), or any other event source that can be represented by an fd. You could start separate threads to handle each event source, but you would have to manage the threads and deal with concurrency issues. The other option would be to use a mechanism where you can aggregate all the fd into a single entity fdset, and then just call a function to wait on the fdset. This function would return whenever an event occurs on any of the fd. You could check which fd the event occurred on, read that fd, process the event, and respond to it. After you have done that, you would go back and sit in that wait function - till another event on some fd arrives.

select facility is such a mechanism, and the select() function is the wait function. You can find the details on how to use it in any number of books and online resources.

Every socket (really, every file descriptor that can be select()ed on) has a list of waiters that are currently waiting for activity on that socket (struct wait_queue_head_t in Linux terminology). Whenever something interesting happens on that socket (new data is available, buffer space is free for writing, or some kind of error), that socket will walk its list and notify everyone waiting on it.

[[quora][https://www.quora.com/Network-Programming-How-is-select-implemented]]
select() works by looping over the list of file descriptors that the user passed in. For every file descriptor, it calls that fd's poll() method, which will add the caller to that fd's wait queue, and return which events (readable, writeable, exception) currently apply to that fd.

If any file descriptor matches the condition that the user was looking for, select() will simply return immediately, after updating the appropriate fd_sets that the user passed.

If not, however, select() will go to sleep, for up to the maximum timeout the user specified.

If, during that interval, an interesting event happens to any file descriptor that select() is waiting on, that fd will notify its wait queue. That will cause the thread sleeping inside select() to wake up, at which point it will repeat the above loop and see which of the fd's are now ready to be returned to the user.

select() also keeps track of all of the wait queues it has been added to, and before returning (successfully or otherwise), must go through and ensure it's been removed from all of them.
